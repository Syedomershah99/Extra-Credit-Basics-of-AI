{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit: Temporal Airbnb Seasonality and Modeling (EAS 510)\n",
    "\n",
    "This notebook:\n",
    "- Builds night-level panel datasets for each city + snapshot\n",
    "- Performs seasonality analysis (required plots)\n",
    "- Builds temporal train/valid/test split (no leakage)\n",
    "- Trains XGBoost + Neural Nets (price regression + booking classification)\n",
    "- Logs Neural Net training with TensorBoard\n",
    "- Summarizes results + provides write-up templates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys, subprocess\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs)\n",
    "\n",
    "pip_install([\"pandas\", \"numpy\", \"matplotlib\", \"scikit-learn\", \"xgboost\", \"tensorflow\", \"pyarrow\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "\n",
    "DATA_ROOT = Path(\".\")\n",
    "print(\"DATA_ROOT:\", DATA_ROOT.resolve())\n",
    "print(\"DATA_ROOT exists?\", DATA_ROOT.exists())\n",
    "\n",
    "if DATA_ROOT.exists():\n",
    "    print(\"Top-level items inside BONUS_ASSIGNMENT:\")\n",
    "    print([p.name for p in DATA_ROOT.iterdir()])\n",
    "else:\n",
    "    print(\"\u274c BONUS_ASSIGNMENT folder not found from this CWD.\")\n",
    "    print(\"Fix by either:\")\n",
    "    print(\"1) Moving notebook to the parent folder of BONUS_ASSIGNMENT, or\")\n",
    "    print(\"2) Setting DATA_ROOT = Path(r'FULL_PATH_TO/BONUS_ASSIGNMENT')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    (\"Austin\", \"3625\"): {\n",
    "        \"calendar\": \"http://data.insideairbnb.com/united-states/tx/austin/2025-03-06/data/calendar.csv.gz\",\n",
    "        \"listings\": \"http://data.insideairbnb.com/united-states/tx/austin/2025-03-06/data/listings.csv.gz\",\n",
    "    },\n",
    "    (\"Austin\", \"121424\"): {\n",
    "        \"calendar\": \"http://data.insideairbnb.com/united-states/tx/austin/2024-12-14/data/calendar.csv.gz\",\n",
    "        \"listings\": \"http://data.insideairbnb.com/united-states/tx/austin/2024-12-14/data/listings.csv.gz\",\n",
    "    },\n",
    "    (\"Chicago\", \"31125\"): {\n",
    "        \"calendar\": \"http://data.insideairbnb.com/united-states/il/chicago/2025-03-11/data/calendar.csv.gz\",\n",
    "        \"listings\": \"http://data.insideairbnb.com/united-states/il/chicago/2025-03-11/data/listings.csv.gz\",\n",
    "    },\n",
    "    (\"Chicago\", \"121824\"): {\n",
    "        \"calendar\": \"http://data.insideairbnb.com/united-states/il/chicago/2024-12-18/data/calendar.csv.gz\",\n",
    "        \"listings\": \"http://data.insideairbnb.com/united-states/il/chicago/2024-12-18/data/listings.csv.gz\",\n",
    "    },\n",
    "    (\"Santa_Cruz\", \"32825\"): {\n",
    "        \"calendar\": \"http://data.insideairbnb.com/united-states/ca/santa-cruz-county/2025-03-28/data/calendar.csv.gz\",\n",
    "        \"listings\": \"http://data.insideairbnb.com/united-states/ca/santa-cruz-county/2025-03-28/data/listings.csv.gz\",\n",
    "    },\n",
    "    (\"Santa_Cruz\", \"123125\"): {\n",
    "        \"calendar\": \"http://data.insideairbnb.com/united-states/ca/santa-cruz-county/2024-12-31/data/calendar.csv.gz\",\n",
    "        \"listings\": \"http://data.insideairbnb.com/united-states/ca/santa-cruz-county/2024-12-31/data/listings.csv.gz\",\n",
    "    },\n",
    "    (\"WashingtonDC\", \"31325\"): {\n",
    "        \"calendar\": \"http://data.insideairbnb.com/united-states/dc/washington-dc/2025-03-13/data/calendar.csv.gz\",\n",
    "        \"listings\": \"http://data.insideairbnb.com/united-states/dc/washington-dc/2025-03-13/data/listings.csv.gz\",\n",
    "    },\n",
    "    (\"WashingtonDC\", \"121825\"): {\n",
    "        \"calendar\": \"http://data.insideairbnb.com/united-states/dc/washington-dc/2024-12-18/data/calendar.csv.gz\",\n",
    "        \"listings\": \"http://data.insideairbnb.com/united-states/dc/washington-dc/2024-12-18/data/listings.csv.gz\",\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"\u2705 Using InsideAirbnb URLs for data fetching.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning plus Category Capping helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price_to_float(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype(str).replace(\"nan\", np.nan)\n",
    "    s = s.str.replace(r\"[$,]\", \"\", regex=True)\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return s\n",
    "\n",
    "def tf_to_int(series: pd.Series) -> pd.Series:\n",
    "    # Handles 't'/'f', True/False, 1/0\n",
    "    if series.dtype == bool:\n",
    "        return series.astype(int)\n",
    "    s = series.astype(str).str.lower()\n",
    "    return s.map({\"t\": 1, \"f\": 0, \"true\": 1, \"false\": 0, \"1\": 1, \"0\": 0}).fillna(0).astype(int)\n",
    "\n",
    "def cap_top_k_categories(df: pd.DataFrame, col: str, k: int = 25) -> pd.DataFrame:\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "    top = df[col].value_counts(dropna=True).head(k).index\n",
    "    df[col] = df[col].where(df[col].isin(top), other=\"Other\")\n",
    "    df[col] = df[col].fillna(\"Missing\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_split_by_month(df: pd.DataFrame, train_months=9, valid_months=2):\n",
    "    df = df.dropna(subset=[\"date\"]).copy()\n",
    "    df[\"year_month\"] = df[\"date\"].dt.to_period(\"M\")\n",
    "\n",
    "    months_sorted = np.array(sorted(df[\"year_month\"].unique()))\n",
    "    if len(months_sorted) < (train_months + valid_months + 1):\n",
    "        raise ValueError(f\"Not enough months in snapshot range: only {len(months_sorted)}\")\n",
    "\n",
    "    train_set = set(months_sorted[:train_months])\n",
    "    valid_set = set(months_sorted[train_months:train_months+valid_months])\n",
    "    test_set  = set(months_sorted[train_months+valid_months:])\n",
    "\n",
    "    train_df = df[df[\"year_month\"].isin(train_set)]\n",
    "    valid_df = df[df[\"year_month\"].isin(valid_set)]\n",
    "    test_df  = df[df[\"year_month\"].isin(test_set)]\n",
    "\n",
    "    return train_df, valid_df, test_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and build panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_snapshot(listings_path: Path, calendar_path: Path):\n",
    "    # Calendar: read required columns (if present)\n",
    "    cal = pd.read_csv(calendar_path, compression=\"gzip\", low_memory=False)\n",
    "    if \"price\" not in cal.columns and \"adjusted_price\" in cal.columns:\n",
    "        cal = cal.rename(columns={\"adjusted_price\": \"price\"})\n",
    "\n",
    "    needed_cal = [\"listing_id\", \"date\", \"available\", \"price\", \"minimum_nights\", \"maximum_nights\"]\n",
    "    keep_cal = [c for c in needed_cal if c in cal.columns]\n",
    "    cal = cal[keep_cal].copy()\n",
    "\n",
    "    # Listings: load then select a safe subset (varies by city)\n",
    "    listings_all = pd.read_csv(listings_path, compression=\"gzip\", low_memory=False)\n",
    "\n",
    "    # Normalize key to listing_id\n",
    "    if \"listing_id\" not in listings_all.columns and \"id\" in listings_all.columns:\n",
    "        listings_all = listings_all.rename(columns={\"id\": \"listing_id\"})\n",
    "\n",
    "    desired_listing_cols = [\n",
    "        \"listing_id\",\n",
    "        \"accommodates\", \"bedrooms\", \"beds\",\n",
    "        \"room_type\", \"property_type\", \"neighbourhood_cleansed\",\n",
    "        \"number_of_reviews\", \"review_scores_rating\",\n",
    "        \"host_is_superhost\", \"instant_bookable\"\n",
    "    ]\n",
    "    keep_list = [c for c in desired_listing_cols if c in listings_all.columns]\n",
    "    listings = listings_all[keep_list].copy()\n",
    "\n",
    "    return listings, cal\n",
    "\n",
    "def build_panel(listings: pd.DataFrame, cal: pd.DataFrame, city: str, snapshot: str,\n",
    "                save_sample_parquet: bool = True, sample_rows: int = 100_000) -> pd.DataFrame:\n",
    "    # Evidence (shapes/head/dtypes)\n",
    "    print(f\"\\n===== {city} | snapshot {snapshot} =====\")\n",
    "    print(\"LISTINGS shape:\", listings.shape)\n",
    "    display(listings.head())\n",
    "    print(listings.dtypes)\n",
    "\n",
    "    print(\"\\nCALENDAR shape:\", cal.shape)\n",
    "    display(cal.head())\n",
    "    print(cal.dtypes)\n",
    "\n",
    "    # Left merge on listing_id (1 row per listing/date)\n",
    "    df = cal.merge(listings, on=\"listing_id\", how=\"left\")\n",
    "\n",
    "    # Clean + transform\n",
    "    df[\"price\"] = clean_price_to_float(df[\"price\"]) if \"price\" in df.columns else np.nan\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "    if \"available\" in df.columns:\n",
    "        df[\"is_booked\"] = (df[\"available\"].astype(str).str.lower() == \"f\").astype(int)\n",
    "    else:\n",
    "        df[\"is_booked\"] = np.nan\n",
    "\n",
    "    # Time features\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"day_of_week\"] = df[\"date\"].dt.dayofweek\n",
    "    df[\"week_of_year\"] = df[\"date\"].dt.isocalendar().week.astype(\"Int64\")\n",
    "    df[\"is_weekend\"] = (df[\"day_of_week\"] >= 5).astype(int)\n",
    "    df[\"day_of_year\"] = df[\"date\"].dt.dayofyear\n",
    "\n",
    "    # Quick verification\n",
    "    print(\"\\nMERGED panel shape:\", df.shape)\n",
    "    show_cols = [c for c in [\"listing_id\",\"date\",\"price\",\"available\",\"is_booked\",\"month\",\"day_of_week\",\"week_of_year\",\"is_weekend\",\"day_of_year\"] if c in df.columns]\n",
    "    display(df[show_cols].head())\n",
    "\n",
    "    # Optional: save sample parquet\n",
    "    # Optional: save sample as CSV.GZ (no pyarrow required)\n",
    "    if save_sample_parquet:\n",
    "        out = DATA_ROOT / f\"panel_{city}_{snapshot}_sample{sample_rows}.csv.gz\"\n",
    "        df.head(sample_rows).to_csv(out, index=False, compression=\"gzip\")\n",
    "        print(\"Saved sample CSV:\", out)\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PANELS = {}\n",
    "\n",
    "for (city, snap), paths in DATASETS.items():\n",
    "    listings, cal = load_snapshot(paths[\"listings\"], paths[\"calendar\"])\n",
    "    panel = build_panel(listings, cal, city, snap, save_sample_parquet=False, sample_rows=100_000)\n",
    "    PANELS[(city, snap)] = panel\n",
    "\n",
    "print(\"\\n\u2705 Built panels:\", len(PANELS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Seasonality Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonality_plots(df: pd.DataFrame, title_prefix: str, listing_type_col: str = \"room_type\"):\n",
    "    df2 = df.dropna(subset=[\"date\", \"price\"]).copy()\n",
    "\n",
    "    # 1) Avg price by month\n",
    "    by_month_price = df2.groupby(\"month\")[\"price\"].mean().sort_index()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(by_month_price.index, by_month_price.values, marker=\"o\")\n",
    "    plt.title(f\"{title_prefix} - Avg Price by Month\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Average Price\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Avg booking probability by month\n",
    "    by_month_book = df2.groupby(\"month\")[\"is_booked\"].mean().sort_index()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(by_month_book.index, by_month_book.values, marker=\"o\")\n",
    "    plt.title(f\"{title_prefix} - Booking Probability by Month\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"P(Booked) = mean(is_booked)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 3) Weekend vs weekday bars (price + booking)\n",
    "    wk = df2.groupby(\"is_weekend\")[[\"price\", \"is_booked\"]].mean().rename(index={0: \"Weekday\", 1: \"Weekend\"})\n",
    "\n",
    "    plt.figure()\n",
    "    plt.bar(wk.index.astype(str), wk[\"price\"].values)\n",
    "    plt.title(f\"{title_prefix} - Weekend vs Weekday Avg Price\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Average Price\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.bar(wk.index.astype(str), wk[\"is_booked\"].values)\n",
    "    plt.title(f\"{title_prefix} - Weekend vs Weekday Booking Probability\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"P(Booked)\")\n",
    "    plt.show()\n",
    "\n",
    "    # 4) Avg price by month grouped by listing type (room_type/property_type/...)\n",
    "    if listing_type_col in df2.columns:\n",
    "        sub = df2.copy()\n",
    "        sub = cap_top_k_categories(sub, listing_type_col, k=6)\n",
    "        g = sub.groupby([\"month\", listing_type_col])[\"price\"].mean().reset_index()\n",
    "\n",
    "        plt.figure()\n",
    "        for cat in g[listing_type_col].unique():\n",
    "            s = g[g[listing_type_col] == cat].sort_values(\"month\")\n",
    "            plt.plot(s[\"month\"], s[\"price\"], marker=\"o\", label=str(cat))\n",
    "        plt.title(f\"{title_prefix} - Avg Price by Month by {listing_type_col}\")\n",
    "        plt.xlabel(\"Month\")\n",
    "        plt.ylabel(\"Average Price\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"(Skipped grouped plot: '{listing_type_col}' not found)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (city, snap), df in PANELS.items():\n",
    "    seasonality_plots(df, f\"{city} | {snap}\", listing_type_col=\"room_type\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Interpretation\n",
    "\n",
    "### Austin | 6 March 2025\n",
    "The average price stays super steady throughout the year, with just tiny ups and downs\u2014there's a slight bump around early fall (like October), and it's a tad lower in the early and late months. But booking probability? That's way more seasonal: it's highest in Jan\u2013Mar, drops hard in Apr\u2013May (bottoming out around May), and then picks up again from late summer into fall and winter. Weekend vs weekday prices are basically the same (no real weekend markup), and weekends book a bit more often. Room type drives price way more than seasonality\u2014hotel rooms are always the priciest, followed by entire homes/apts, private rooms, and shared rooms last, and these stay pretty flat month to month.\n",
    "\n",
    "### Austin | 14 December 2024\n",
    "Prices are really flat here too, with a gentle climb from winter into spring/summer and a small dip in December. Booking probability has a clear upward trend: it's lower in Jan\u2013Feb, builds steadily through spring and summer, peaks around Oct\u2013Nov, and drops a little in December. Weekend vs weekday prices are almost identical, with maybe a tiny weekend boost if anything. Room types keep the same order (hotel highest, entire home/apt next, private, then shared), and they're stable across months, so room type wins over seasonal changes.\n",
    "\n",
    "### Chicago | 11 March 2025\n",
    "Prices have a noticeable jump in Apr\u2013May compared to the rest of the year, then level out from summer through December. Booking probability starts high in Jan\u2013Mar, plunges in Apr\u2013May, hits its lowest around August, and bounces back in fall/winter (with December above the mid-year low). Weekends show a small lift for both price and booking (weekends edge out a bit). Room types are clearly separated and mostly steady: entire homes/apts top the list, hotels next, shared rooms surprisingly high relative to private, and private lowest\u2014the lines are flat, meaning not much monthly variation within types.\n",
    "\n",
    "### Chicago | 18 December 2024\n",
    "Prices rise from winter into spring/summer (peaking Mar\u2013Jul), then drop starting in August and bottom out in December. Booking probability is strongly seasonal: lowest in winter (especially Feb), climbing through late spring/summer, and peaking Oct\u2013Dec (around 0.5). Weekend prices are a touch higher, and weekend bookings too. Room types are mostly stable, with entire homes/apts and hotels priciest, private lowest, and shared in the middle\u2014but hotels dip noticeably in December, maybe due to end-of-year deals or shifts in listings.\n",
    "\n",
    "### Santa_Cruz | 28 March 2025\n",
    "Prices are almost perfectly flat, except for a clear dip around March before leveling back up. Booking probability is super seasonal: highest Jan\u2013Mar, crashing in April (lowest around May), then recovering a bit in early summer and again toward year-end. Weekend vs weekday prices are the same (no weekend premium), but weekends book slightly more. Room types are consistent: hotels highest, entire homes/apts next, private cheaper, shared lowest, with just a dip for private rooms around March.\n",
    "\n",
    "### Santa_Cruz | 31 December 2025\n",
    "Prices hold steady most of the year, with a small drop in December. Booking probability bottoms out in late winter/early spring (Feb\u2013Mar), rises slowly through spring, spikes around July, and stays high into fall/winter (peaking Oct\u2013Dec). Weekend vs weekday prices are nearly identical, and weekend bookings are a bit higher. Room types are flat overall (hotels top, entire homes/apts next, private, then shared), but private rooms dip in December, echoing the general trend.\n",
    "\n",
    "### WashingtonDC | 13 March 2025\n",
    "Prices are basically flat all year, with a tiny dip around March\u2014super weak seasonality. Booking probability peaks in March, declines steadily into summer (lowest in August), then rebounds in fall and ends strong in December. Weekend vs weekday prices are the same, and weekends book a tad more. Room types dominate: shared rooms are insanely expensive (a big outlier), entire homes/apts and hotels mid-high, private lowest and trends are mostly steady month to month.\n",
    "\n",
    "### WashingtonDC | 18 December 2025\n",
    "Prices stay flat with a slight December drop. Booking probability is low in winter (especially Feb), then climbs through spring/summer, hitting highs in Oct\u2013Dec. Weekend vs weekday prices are almost identical, and weekend bookings slightly higher. Room types are separated and stable: shared rooms as outliers (super high), entire homes/apts and hotels next, private lowest\u2014category differences dwarf monthly changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choosing one dataset for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling is required for both targets; the rubric does NOT require running models for all 8 datasets.\n",
    "# Pick one dataset key here.\n",
    "MODEL_KEY = (\"Austin\", \"3625\")  # change if you want\n",
    "\n",
    "df_model = panel_df.copy()\n",
    "print(\"Using MODEL_KEY:\", MODEL_KEY, \"| rows:\", len(df_model))\n",
    "display(df_model.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_split_by_month(df: pd.DataFrame, train_months=9, valid_months=2):\n",
    "    df = df.dropna(subset=[\"date\"]).copy()\n",
    "    df[\"year_month\"] = df[\"date\"].dt.to_period(\"M\")\n",
    "    months_sorted = np.array(sorted(df[\"year_month\"].unique()))\n",
    "\n",
    "    if len(months_sorted) < (train_months + valid_months + 1):\n",
    "        raise ValueError(f\"Not enough months in snapshot range: only {len(months_sorted)}\")\n",
    "\n",
    "    train_set = set(months_sorted[:train_months])\n",
    "    valid_set = set(months_sorted[train_months:train_months+valid_months])\n",
    "    test_set  = set(months_sorted[train_months+valid_months:])\n",
    "\n",
    "    train_df = df[df[\"year_month\"].isin(train_set)].copy()\n",
    "    valid_df = df[df[\"year_month\"].isin(valid_set)].copy()\n",
    "    test_df  = df[df[\"year_month\"].isin(test_set)].copy()\n",
    "\n",
    "    print(\"Train months:\", sorted(train_set)[:3], \"...\", sorted(train_set)[-3:])\n",
    "    print(\"Valid months:\", sorted(valid_set))\n",
    "    print(\"Test months:\", sorted(test_set)[:3], \"...\", sorted(test_set)[-3:])\n",
    "    print(\"Shapes:\", train_df.shape, valid_df.shape, test_df.shape)\n",
    "\n",
    "    return train_df, valid_df, test_df\n",
    "\n",
    "train_df, valid_df, test_df = temporal_split_by_month(df_model, train_months=9, valid_months=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection and Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean booleans / cap categories for modeling\n",
    "for d in [train_df, valid_df, test_df]:\n",
    "    if \"host_is_superhost\" in d.columns:\n",
    "        d[\"host_is_superhost\"] = tf_to_int(d[\"host_is_superhost\"])\n",
    "    if \"instant_bookable\" in d.columns:\n",
    "        d[\"instant_bookable\"] = tf_to_int(d[\"instant_bookable\"])\n",
    "    if \"room_type\" in d.columns:\n",
    "        d = cap_top_k_categories(d, \"room_type\", k=6)\n",
    "    if \"property_type\" in d.columns:\n",
    "        d = cap_top_k_categories(d, \"property_type\", k=10)\n",
    "    if \"neighbourhood_cleansed\" in d.columns:\n",
    "        d = cap_top_k_categories(d, \"neighbourhood_cleansed\", k=25)\n",
    "\n",
    "# Choose candidate features (only those that exist)\n",
    "candidate_numeric = [\n",
    "    \"accommodates\", \"bedrooms\", \"beds\",\n",
    "    \"number_of_reviews\", \"review_scores_rating\",\n",
    "    \"minimum_nights\", \"maximum_nights\",\n",
    "    \"month\", \"day_of_week\", \"week_of_year\", \"is_weekend\", \"day_of_year\",\n",
    "    \"host_is_superhost\", \"instant_bookable\",\n",
    "]\n",
    "candidate_categ = [\"room_type\", \"property_type\", \"neighbourhood_cleansed\"]\n",
    "\n",
    "numeric_features = [c for c in candidate_numeric if c in df_model.columns]\n",
    "categorical_features = [c for c in candidate_categ if c in df_model.columns]\n",
    "\n",
    "# Targets\n",
    "target_price = \"price\"\n",
    "target_book = \"is_booked\"\n",
    "\n",
    "# Drop rows missing targets\n",
    "train_df = train_df.dropna(subset=[target_price, target_book]).copy()\n",
    "valid_df = valid_df.dropna(subset=[target_price, target_book]).copy()\n",
    "test_df  = test_df.dropna(subset=[target_price, target_book]).copy()\n",
    "\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "print(\"\\nTrain/Valid/Test target availability:\")\n",
    "print(train_df[[target_price, target_book]].isna().mean())\n",
    "print(valid_df[[target_price, target_book]].isna().mean())\n",
    "print(test_df[[target_price, target_book]].isna().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df(df: pd.DataFrame, n: int, seed=RANDOM_STATE):\n",
    "    if len(df) <= n:\n",
    "        return df\n",
    "    return df.sample(n=n, random_state=seed)\n",
    "\n",
    "MAX_TRAIN = 250_000\n",
    "MAX_VALID = 75_000\n",
    "MAX_TEST  = 75_000\n",
    "\n",
    "train_s = sample_df(train_df, MAX_TRAIN)\n",
    "valid_s = sample_df(valid_df, MAX_VALID)\n",
    "test_s  = sample_df(test_df,  MAX_TEST)\n",
    "\n",
    "print(\"Sampled shapes:\", train_s.shape, valid_s.shape, test_s.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14 (UPDATED FULL) \u2014 Preprocessor + matrices (fix mixed int/str categorical)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# OneHotEncoder compatibility across sklearn versions\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "# \u2705 FIX: force categorical cols to be strings (prevents int/str mix error)\n",
    "for df_ in (train_s, valid_s, test_s):\n",
    "    for col in categorical_features:\n",
    "        if col in df_.columns:\n",
    "            df_[col] = df_[col].astype(\"string\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", ohe),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_train = preprocessor.fit_transform(train_s)\n",
    "X_valid = preprocessor.transform(valid_s)\n",
    "X_test  = preprocessor.transform(test_s)\n",
    "\n",
    "y_train_price = train_s[target_price].astype(float).values\n",
    "y_valid_price = valid_s[target_price].astype(float).values\n",
    "y_test_price  = test_s[target_price].astype(float).values\n",
    "\n",
    "y_train_book = train_s[target_book].astype(int).values\n",
    "y_valid_book = valid_s[target_book].astype(int).values\n",
    "y_test_book  = test_s[target_book].astype(int).values\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"dtype:\", X_train.dtype)\n",
    "print(\"X_valid shape:\", X_valid.shape)\n",
    "print(\"X_test  shape:\", X_test.shape)\n",
    "print(\"y_train_price:\", y_train_price.shape, \"y_train_book:\", y_train_book.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regression on Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = XGBRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "xgb_reg.fit(\n",
    "    X_train, y_train_price,\n",
    "    eval_set=[(X_valid, y_valid_price)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "pred_test_price = xgb_reg.predict(X_test)\n",
    "rmse = (mean_squared_error(y_test_price, pred_test_price)) ** 0.5\n",
    "mae = mean_absolute_error(y_test_price, pred_test_price)\n",
    "\n",
    "print(\"XGB REG | Test RMSE:\", rmse)\n",
    "print(\"XGB REG | Test MAE :\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(preprocessor, numeric_features, categorical_features):\n",
    "    names = []\n",
    "    names += list(numeric_features)\n",
    "\n",
    "    if categorical_features:\n",
    "        ohe_step = preprocessor.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "        names += ohe_step.get_feature_names_out(categorical_features).tolist()\n",
    "\n",
    "    return names\n",
    "\n",
    "feature_names = get_feature_names(preprocessor, numeric_features, categorical_features)\n",
    "print(\"\u2705 feature_names ready. Count:\", len(feature_names), \"| X width:\", X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = xgb_reg.feature_importances_\n",
    "imp_df = pd.DataFrame({\"feature\": feature_names, \"importance\": importances}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "display(imp_df.head(20))\n",
    "\n",
    "topk = 25\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.barh(imp_df.head(topk)[\"feature\"][::-1], imp_df.head(topk)[\"importance\"][::-1])\n",
    "plt.title(\"XGBoost Regressor - Top Feature Importances\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classification (is_booked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = y_train_book.sum()\n",
    "neg = len(y_train_book) - pos\n",
    "scale_pos_weight = (neg / pos) if pos > 0 else 1.0\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric=\"logloss\",\n",
    ")\n",
    "\n",
    "xgb_clf.fit(\n",
    "    X_train, y_train_book,\n",
    "    eval_set=[(X_valid, y_valid_book)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "proba_test = xgb_clf.predict_proba(X_test)[:, 1]\n",
    "pred_test = (proba_test >= 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_test_book, proba_test)\n",
    "acc = accuracy_score(y_test_book, pred_test)\n",
    "\n",
    "print(\"XGB CLF | Test AUC     :\", auc)\n",
    "print(\"XGB CLF | Test Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = xgb_clf.feature_importances_\n",
    "imp_df2 = pd.DataFrame({\"feature\": feature_names, \"importance\": importances}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "display(imp_df2.head(20))\n",
    "\n",
    "topk = 25\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.barh(imp_df2.head(topk)[\"feature\"][::-1], imp_df2.head(topk)[\"importance\"][::-1])\n",
    "plt.title(\"XGBoost Classifier - Top Feature Importances\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nn_reg(input_dim: int):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def make_nn_clf(input_dim: int):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[keras.metrics.AUC(name=\"auc\"), \"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def timestamp_str():\n",
    "    return datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "INPUT_DIM = X_train.shape[1]\n",
    "\n",
    "# Separate log dirs (required)\n",
    "logdir_price = LOGS_DIR / \"nn_price\" / f\"{MODEL_KEY[0]}_{MODEL_KEY[1]}\" / timestamp_str()\n",
    "logdir_book  = LOGS_DIR / \"nn_book\"  / f\"{MODEL_KEY[0]}_{MODEL_KEY[1]}\" / timestamp_str()\n",
    "logdir_price.mkdir(parents=True, exist_ok=True)\n",
    "logdir_book.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cb_price = [\n",
    "    keras.callbacks.TensorBoard(log_dir=str(logdir_price)),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
    "]\n",
    "cb_book = [\n",
    "    keras.callbacks.TensorBoard(log_dir=str(logdir_book)),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "nn_reg = make_nn_reg(INPUT_DIM)\n",
    "hist_reg = nn_reg.fit(\n",
    "    X_train, y_train_price,\n",
    "    validation_data=(X_valid, y_valid_price),\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    callbacks=cb_price,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "nn_clf = make_nn_clf(INPUT_DIM)\n",
    "hist_clf = nn_clf.fit(\n",
    "    X_train, y_train_book,\n",
    "    validation_data=(X_valid, y_valid_book),\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    callbacks=cb_book,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\u2705 NN training done.\")\n",
    "print(\"NN PRICE logdir:\", logdir_price)\n",
    "print(\"NN BOOK  logdir:\", logdir_book)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Neural Net on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression metrics\n",
    "pred_nn_price = nn_reg.predict(X_test).ravel()\n",
    "rmse_nn = mean_squared_error(y_test_price, pred_nn_price) ** 0.5\n",
    "mae_nn = mean_absolute_error(y_test_price, pred_nn_price)\n",
    "\n",
    "print(\"NN REG | Test RMSE:\", rmse_nn)\n",
    "print(\"NN REG | Test MAE :\", mae_nn)\n",
    "\n",
    "# Classification metrics\n",
    "proba_nn = nn_clf.predict(X_test).ravel()\n",
    "pred_nn = (proba_nn >= 0.5).astype(int)\n",
    "\n",
    "auc_nn = roc_auc_score(y_test_book, proba_nn)\n",
    "acc_nn = accuracy_score(y_test_book, pred_nn)\n",
    "\n",
    "print(\"NN CLF | Test AUC     :\", auc_nn)\n",
    "print(\"NN CLF | Test Accuracy:\", acc_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 TensorBoard Screenshots (Required)\n",
    "\n",
    "### NN Price (Regression) \u2014 TensorBoard Scalars Screenshot\n",
    "\n",
    "<img src=\"Tensorboard_SS/epoch_loss_R.png\" width=\"1040\">\n",
    "<img src=\"Tensorboard_SS/epoch_mae_R.png\" width=\"1040\">\n",
    "<img src=\"Tensorboard_SS/epoch_loss_itr_R.png\" width=\"1040\">\n",
    "<img src=\"Tensorboard_SS/epoch_mae_itr_R.png\" width=\"1040\">\n",
    "\n",
    "\n",
    "### NN Booking (Classification) \u2014 TensorBoard Scalars Screenshot\n",
    "\n",
    "<img src=\"Tensorboard_SS/epoch_accuracy_C.png\" width=\"1040\">\n",
    "<img src=\"Tensorboard_SS/epoch_auc_C.png\" width=\"1040\">\n",
    "<img src=\"Tensorboard_SS/epoch_acc_itr_C.png\" width=\"1040\">\n",
    "<img src=\"Tensorboard_SS/epoch_auc_itr_C.png\" width=\"1040\">\n",
    "\n",
    "## Part 4 Discussion\n",
    "\n",
    "For the price regression NN, both training and validation loss/MAE decrease smoothly and stay fairly close, which suggests stable training and only mild overfitting. The evaluation loss/MAE vs iterations curves also trend down steadily without big spikes, so optimization looks stable (no major divergence or instability). Overall, validation continues improving through the last epoch, so more epochs (with early stopping) could potentially help a bit more.  \n",
    "For the booking classification NN, training accuracy/AUC increase noticeably faster than validation, and the train\u2013validation gap grows by the final epoch, which indicates overfitting. Validation accuracy/AUC improve only modestly (and start to flatten), meaning generalization is the bottleneck rather than training performance. This pattern is consistent with booking being a noisier/harder target than price (often more imbalance and weaker signal), so it tends to need stronger regularization and careful early stopping based on validation AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([\n",
    "    {\"model\": \"XGB_REG\", \"target\": \"price\", \"RMSE\": rmse, \"MAE\": mae, \"AUC\": np.nan, \"ACC\": np.nan},\n",
    "    {\"model\": \"XGB_CLF\", \"target\": \"is_booked\", \"RMSE\": np.nan, \"MAE\": np.nan, \"AUC\": auc, \"ACC\": acc},\n",
    "    {\"model\": \"NN_REG\",  \"target\": \"price\", \"RMSE\": rmse_nn, \"MAE\": mae_nn, \"AUC\": np.nan, \"ACC\": np.nan},\n",
    "    {\"model\": \"NN_CLF\",  \"target\": \"is_booked\", \"RMSE\": np.nan, \"MAE\": np.nan, \"AUC\": auc_nn, \"ACC\": acc_nn},\n",
    "])\n",
    "\n",
    "print(\"MODEL_KEY:\", MODEL_KEY)\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Interpretation\n",
    "\n",
    "### Austin | 6 March 2025\n",
    "\n",
    "Average price is almost flat across the year, with only tiny bumps (slight peak around Oct and a small dip around Mar). Booking probability is clearly seasonal: it\u2019s highest in Jan\u2013Mar, drops hard around Apr\u2013May, then climbs again in the fall and ends stronger in Dec. Weekends vs weekdays show almost no price difference, and weekends have a slightly higher booking probability. By room type, **Hotel room** is the most expensive, then **Entire home/apt**, then **Private room**, and **Shared room** (and these lines are very stable month-to-month).\n",
    "\n",
    "### Austin | 14 December 2024\n",
    "\n",
    "Price is very steady with a gentle rise from early months into spring/summer and a noticeable dip in December. Booking probability trends upward through the year, peaking around Oct\u2013Nov and staying relatively high into Dec compared to early months. Weekend vs weekday pricing is nearly identical, with only a tiny weekend lift (if any). Room-type pricing shows the same consistent ranking (Hotel > Entire home/apt > Private > Shared) with minimal seasonality in price.\n",
    "\n",
    "### Chicago | 11 March 2025\n",
    "\n",
    "Prices show a small spring peak (around Apr\u2013May) followed by a dip in early summer (Jun\u2013Jul), then stabilize for the rest of the year. Booking probability is highest in late winter/early spring (peaking around Mar), drops to its lowest point around Aug, then recovers in the fall and rises into Dec. Weekend vs weekday average price is nearly the same, while weekends book slightly more often than weekdays. Room types are strongly separated in price (Entire home/apt highest; Private room lowest), and they stay mostly flat across months.\n",
    "\n",
    "### Chicago | 18 December 2024\n",
    "\n",
    "Average price jumps up around Mar and remains relatively stable through mid-year, then steps down around Aug\u2013Nov and drops more noticeably in Dec. Booking probability starts low early in the year (lowest around Feb), then steadily rises from late spring onward and peaks around Oct\u2013Dec. Weekday vs weekend prices are almost identical, and weekend booking probability is only slightly higher. Room-type prices are mostly stable, but **December shows a noticeable drop for Hotel room (and a small drop for Private room)** compared to the rest of the year.\n",
    "\n",
    "### Santa_Cruz | 28 March 2025\n",
    "\n",
    "Average price is essentially flat, except for a clear dip around March before returning to the normal level. Booking probability is highest in Jan\u2013Mar, falls sharply around Apr\u2013May, then partially rebounds in summer and increases again toward year-end. Weekend vs weekday price is almost unchanged, while weekends book a bit more often. Room-type differences are large and consistent (Hotel highest; Shared lowest), and Private room shows a visible dip around March similar to the overall pattern.\n",
    "\n",
    "### Santa_Cruz | 31 December 2025\n",
    "\n",
    "Prices are very stable through most of the year, with a noticeable drop in December. Booking probability is lowest around Feb\u2013Mar, rises slowly through spring, then jumps strongly around July and peaks again in Oct\u2013Dec. Weekday vs weekend price is basically the same, and weekend booking probability is slightly higher. Room-type ranking is stable, but **Private room drops in December**, matching the overall dip.\n",
    "\n",
    "### WashingtonDC | 13 March 2025\n",
    "\n",
    "Average price is almost perfectly flat, with a small dip around March. Booking probability peaks around March, then steadily declines to the lowest point in August before recovering into the fall and ending higher in December. Weekend vs weekday prices are essentially identical, while weekend booking probability is a bit higher. Room-type prices are separated, but **Shared room is an extreme outlier (very high)**, which likely comes from a small number of listings or noisy data.\n",
    "\n",
    "### WashingtonDC | 18 December 2025\n",
    "\n",
    "Price stays flat throughout the year and drops slightly in December. Booking probability is low in February, then rises steadily through the year and peaks around Oct\u2013Dec. Weekday vs weekend prices are nearly identical and weekend booking probability is slightly higher. Room-type prices are consistent, and again **Shared room looks like a very large outlier**, suggesting potential data quality / small-sample effects.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 4 TensorBoard Screenshots \n",
    "\n",
    "### NN Price (Regression) \u2014 TensorBoard Scalars Screenshot\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"Tensorboard_SS/epoch_loss_R.png\" width=\"360\"/>\n",
    "  <img src=\"Tensorboard_SS/epoch_loss_itr_R.png\" width=\"360\"/>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <img src=\"Tensorboard_SS/epoch_mae_R.png\" width=\"360\"/>\n",
    "  <img src=\"Tensorboard_SS/epoch_mae_itr_R.png\" width=\"360\"/>\n",
    "</p>\n",
    "\n",
    "### NN Booking (Classification) \u2014 TensorBoard Scalars Screenshot\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"Tensorboard_SS/epoch_accuracy_C.png\" width=\"360\"/>\n",
    "  <img src=\"Tensorboard_SS/epoch_acc_itr_C.png\" width=\"360\"/>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <img src=\"Tensorboard_SS/epoch_auc_C.png\" width=\"360\"/>\n",
    "  <img src=\"Tensorboard_SS/epoch_auc_itr_C.png\" width=\"360\"/>\n",
    "</p>\n",
    "\n",
    "## Part 4 Discussion\n",
    "\n",
    "The regression TensorBoard curves show training and validation loss/MAE decreasing smoothly, which suggests stable optimization with no exploding or oscillating behavior. Validation stays close to training, so there is no severe overfitting, but the validation curve generally sits a bit higher, indicating a small generalization gap. For classification, accuracy and AUC increase over epochs, and validation remains consistently below training, which points to mild overfitting or simply that the task is harder to generalize. The curves improve early and then start to flatten, suggesting the model is approaching its best performance under the current architecture and hyperparameters. These TensorBoard trends match the final test metrics: the NN performs reasonably, but it does not beat XGBoost, especially on regression. Overall, the booking model shows clean learning with AUC rising, while the price model still ends with relatively large error, implying feature interactions and nonlinearities may be better captured by tree boosting here.\n",
    "\n",
    "---\n",
    "\n",
    "# Part 5 Final Write-Up (Required)\n",
    "\n",
    "## Data summary + seasonality (prices + bookings)\n",
    "\n",
    "Across all cities and snapshots, average prices exhibit remarkable stability month-to-month, with only minor fluctuations, such as occasional December declines and March dips. In contrast, booking probability demonstrates stronger seasonal patterns: it begins high in January\u2013March, declines during the middle months, and recovers toward October\u2013December, although variations occur by city and snapshot. Weekend versus weekday effects are minimal: prices remain nearly identical, while weekend booking probability is slightly elevated. Room type emerges as a primary determinant of price, with hotel rooms and entire homes/apartments consistently the most expensive, followed by private rooms, and shared rooms the least. WashingtonDC presents an exception, where shared room prices appear as significant outliers, likely due to small sample sizes or data noise, necessitating careful handling.\n",
    "\n",
    "## Temporal modeling setup (no leakage)\n",
    "\n",
    "A chronological split by month was employed to ensure the model learns exclusively from historical data and evaluates on future periods. Specifically, earlier months form the training set, the subsequent months the validation set (for hyperparameter tuning and early stopping), and the final months the test set (for unbiased assessment). This approach prevents leakage, as future calendar outcomes do not influence model fitting or preprocessing. It aligns with real-world deployment, where predictions rely on observed historical patterns. All preprocessing steps, including imputation, scaling, and one-hot encoding, are fitted solely on the training data and applied to validation and test sets.\n",
    "\n",
    "## Model comparison (XGBoost vs Neural Nets)\n",
    "\n",
    "For price prediction (regression), XGBoost significantly outperforms the neural network: XGBoost achieves RMSE = 356 and MAE = 129.9, whereas the neural network yields RMSE = 751 and MAE = 216. In booking prediction (classification), XGBoost maintains superiority, though the margin is narrower: XGBoost attains AUC = 0.734 and Accuracy = 0.677, compared to the neural network's AUC = 0.703 and Accuracy = 0.662. This indicates that booking prediction derives less benefit from deep learning in this context, while tree boosting effectively captures nonlinear feature interactions. Overall, the results suggest that XGBoost serves as the stronger baseline for this tabular panel data across both targets.\n",
    "\n",
    "## TensorBoard insights\n",
    "\n",
    "The regression loss and MAE curves decline steadily for both training and validation sets, indicating stable training and progressive improvement, though they plateau at levels consistent with the neural network's elevated test errors. The classification curves show increases in accuracy and AUC over epochs, with validation consistently below training, suggesting mild overfitting or challenges in generalization. The curves remain smooth without instability, implying that underperformance stems from model fit rather than training issues. These TensorBoard trends correspond to the final metrics: the neural network captures useful signals but underperforms relative to XGBoost. Potential improvements include enhanced regularization, architectures better suited to tabular data, or additional feature engineering.\n",
    "\n",
    "## Business insights\n",
    "\n",
    "Predicting booking probability holds substantial operational value, as it estimates demand and informs dynamic pricing, minimum-night policies, staffing, and marketing strategies. Price prediction remains beneficial for hosts as a market benchmark (\"What price should this listing command?\"), yet demand ultimately drives revenue. Given that weekend booking probability is marginally higher while prices remain unchanged, opportunities exist for hosts to adjust weekend pricing upward during peak seasons. Room type represents a key differentiator, enabling hosts to emphasize attributes such as instant booking or superhost status to compete within their category. Finally, the anomalous shared-room prices in WashingtonDC warrant monitoring, with recommendations for outlier detection and robust data cleaning or minimum-support thresholds prior to automated pricing applications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}